{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBULLJEgLLig"
      },
      "source": [
        "## Implementação de um Classificador Perceptron e Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aB9Mw6rLLij"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Perceptron(object):\n",
        "    \"\"\"Perceptron classifier.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    eta : float\n",
        "      Learning rate (between 0.0 and 1.0)\n",
        "    n_iter : int\n",
        "      Passes over the training dataset.\n",
        "    random_state : int\n",
        "      Random number generator seed for random weight\n",
        "      initialization.\n",
        "\n",
        "    Attributes\n",
        "    -----------\n",
        "    w_ : 1d-array\n",
        "      Weights after fitting.\n",
        "    errors_ : list\n",
        "      Number of misclassifications (updates) in each epoch.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit training data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like}, shape = [n_examples, n_features]\n",
        "          Training vectors, where n_examples is the number of examples and\n",
        "          n_features is the number of features.\n",
        "        y : array-like, shape = [n_examples]\n",
        "          Target values.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "\n",
        "        \"\"\"\n",
        "        rgen = np.random.RandomState(self.random_state)\n",
        "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
        "        self.errors_ = []\n",
        "\n",
        "        for _ in range(self.n_iter):\n",
        "            errors = 0\n",
        "            for xi, target in zip(X, y):\n",
        "                update = self.eta * (target - self.predict(xi))\n",
        "                self.w_[1:] += update * xi\n",
        "                self.w_[0] += update\n",
        "                errors += int(update != 0.0)\n",
        "            self.errors_.append(errors)\n",
        "        return self\n",
        "\n",
        "    def net_input(self, X):\n",
        "        \"\"\"Calculate net input\"\"\"\n",
        "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Return class label after unit step\"\"\"\n",
        "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUlwedZ1LLil"
      },
      "source": [
        "## Testando o classificador Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "olPQJh13LLim",
        "outputId": "6c4e5cf2-a0ea-4813-bba7-cb80a40f4858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado da Predição [-1  1 -1]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Dados de Treinamento \"\"\"\n",
        "X = np.array([[1,1],[2,2],[3,3]])\n",
        "y = np.array([1,1,-1])\n",
        "\n",
        "\"\"\"Criando objeto Perceptron\"\"\"\n",
        "ppn = Perceptron(eta=0.1, n_iter=100)\n",
        "\n",
        "\"\"\"Treinando o modelo\"\"\"\n",
        "ppn.fit(X, y)\n",
        "\n",
        "\"\"\"Testando modelo treinado \"\"\"\n",
        "X_newdata = np.array([[4,4],[2,2],[3,3]])\n",
        "print(\"Resultado da Predição\",ppn.predict(X_newdata));"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questao 1 - Implementar o modelo Multilayer Perceptron (MLP) e testar este classificador"
      ],
      "metadata": {
        "id": "mFtUROu_LtZy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JnFyDudY8N6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Modelo de regressão mlp com loss\n",
        "import numpy as np\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        self.activations = []\n",
        "\n",
        "        # Inicialização dos pesos e biases\n",
        "        for i in range(len(layers) - 1):\n",
        "            weight_matrix = np.random.randn(layers[i + 1], layers[i])\n",
        "            bias_vector = np.zeros((layers[i + 1], 1))\n",
        "            self.weights.append(weight_matrix)\n",
        "            self.biases.append(bias_vector)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def feedforward(self, x):\n",
        "        activation = x\n",
        "        self.activations = [np.array(activation)]  # Convert to numpy array\n",
        "\n",
        "        for i in range(len(self.weights)):\n",
        "            weighted_input = np.dot(self.weights[i], activation) + self.biases[i]\n",
        "            activation = self.sigmoid(weighted_input)\n",
        "            self.activations.append(np.array(activation))  # Convert to numpy array\n",
        "\n",
        "        return activation\n",
        "\n",
        "    def softmax(x):\n",
        "      exponent = np.exp(x) # only compute the exponent once\n",
        "      return exponent/exponent.sum(axis=1,keepdims=True)\n",
        "\n",
        "    def train(self, x_train, y_train, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            for x, y in zip(x_train, y_train):\n",
        "                # Forward propagation\n",
        "                self.feedforward(x)\n",
        "\n",
        "                # Backpropagation\n",
        "                error = y - self.activations[-1]\n",
        "                delta = error * self.activations[-1] * (1 - self.activations[-1])\n",
        "\n",
        "                for i in range(len(self.weights) - 1, -1, -1):\n",
        "                    gradient = learning_rate * np.dot(delta, self.activations[i].T)\n",
        "                    self.weights[i] += gradient\n",
        "                    self.biases[i] += learning_rate * np.mean(delta, axis=1, keepdims=True)\n",
        "\n",
        "                    error = np.dot(self.weights[i].T, delta)\n",
        "                    delta = error * self.activations[i] * (1 - self.activations[i])\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.feedforward(x)\n"
      ],
      "metadata": {
        "id": "MtpvmzjMMEeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        self.activations = []\n",
        "\n",
        "        # Inicialização dos pesos e biases\n",
        "        for i in range(len(layers) - 1):\n",
        "            weight_matrix = np.random.randn(layers[i + 1], layers[i])\n",
        "            bias_vector = np.zeros((layers[i + 1], 1))\n",
        "            self.weights.append(weight_matrix)\n",
        "            self.biases.append(bias_vector)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exponent = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exponent / np.sum(exponent, axis=1, keepdims=True)\n",
        "\n",
        "    def feedforward(self, x):\n",
        "        activation = x\n",
        "        self.activations = [np.array(activation)]  # Convert to numpy array\n",
        "\n",
        "        for i in range(len(self.weights)):\n",
        "            weighted_input = np.dot(self.weights[i], activation) + self.biases[i]\n",
        "            activation = self.sigmoid(weighted_input)\n",
        "            self.activations.append(np.array(activation))  # Convert to numpy array\n",
        "\n",
        "        return activation\n",
        "\n",
        "    def cross_entropy_loss(self, y_pred, y_true):\n",
        "        epsilon = 1e-10\n",
        "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "        loss = -np.sum(y_true * np.log(y_pred)) / len(y_pred)\n",
        "        return loss\n",
        "\n",
        "    def train(self, x_train, y_train, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            for x, y in zip(x_train, y_train):\n",
        "                # Forward propagation\n",
        "                output = self.feedforward(x)\n",
        "                y_pred = self.softmax(output)\n",
        "\n",
        "                # Backpropagation\n",
        "                error = y_pred - y\n",
        "                delta = error\n",
        "\n",
        "                for i in range(len(self.weights) - 1, -1, -1):\n",
        "                    gradient = learning_rate * np.dot(delta, self.activations[i].T)\n",
        "                    self.weights[i] -= gradient\n",
        "                    self.biases[i] -= learning_rate * np.mean(delta, axis=1, keepdims=True)\n",
        "\n",
        "                    error = np.dot(self.weights[i].T, delta)\n",
        "                    delta = error\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.feedforward(x)\n"
      ],
      "metadata": {
        "id": "peMmZII38uVU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzEV7X75LLin"
      },
      "source": [
        "## Questao 2a - Implemente uma função para calcular a acurácia dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeyLTsqdLLin"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.train(x,y,5,0.5)"
      ],
      "metadata": {
        "id": "D4GZd0zYPLdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uDmYfXRMJcPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2hUFeRALLin"
      },
      "source": [
        "## Questao 2b - Implemente um método de validação cruzada para testar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Sigt31YLLio"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wot2pETzLLio"
      },
      "source": [
        "## Questao 2c - Teste os classificadores usando um conjunto de dados linearmente separável e outro não linearmente separável\n",
        "### Sugestão: crie datasets sintéticos com apenas dois atributos para voce poder visualizar a separação das classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYpBpQv4LLio"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}